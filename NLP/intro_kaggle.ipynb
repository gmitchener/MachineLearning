{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tea is healthy and calming, don't you think?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tea\n",
      "is\n",
      "healthy\n",
      "and\n",
      "calming\n",
      ",\n",
      "do\n",
      "n't\n",
      "you\n",
      "think\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\r\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing\r\n",
    "Each word can be broken down into its 'lemma' (base word). We can also identify stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token \t\tLemma \t\tStopword\n",
      "----------------------------------------\n",
      "Tea\t\ttea\t\tFalse\n",
      "is\t\tbe\t\tTrue\n",
      "healthy\t\thealthy\t\tFalse\n",
      "and\t\tand\t\tTrue\n",
      "calming\t\tcalming\t\tFalse\n",
      ",\t\t,\t\tFalse\n",
      "do\t\tdo\t\tTrue\n",
      "n't\t\tn't\t\tTrue\n",
      "you\t\tyou\t\tTrue\n",
      "think\t\tthink\t\tFalse\n",
      "?\t\t?\t\tFalse\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\r\n",
    "print(\"-\"*40)\r\n",
    "for token in doc:\r\n",
    "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Matching\r\n",
    "Matching words or phrases with chunks of text or whole documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\r\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the attribute to LOWER will match on lowercased text, so we have a case insensetive matcher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\r\n",
    "patterns = [nlp(text) for text in terms]\r\n",
    "matcher.add(\"TerminologyList\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n"
     ]
    }
   ],
   "source": [
    "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\r\n",
    "               \"photography tests pitting the iPhone 11 Pro against the \"\r\n",
    "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\") \r\n",
    "matches = matcher(text_doc)\r\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a tuple of match ID and position of the start and end of the phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3766102292120407359 17 19\n",
      "TerminologyList iPhone 11\n"
     ]
    }
   ],
   "source": [
    "matchid, start, end = matches[0]\r\n",
    "print(matchid, start, end)\r\n",
    "print(nlp.vocab.strings[matchid], text_doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\r\n",
    "## Find items in one review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\r\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\r\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\r\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\r\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\r\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\r\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\r\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \r\n",
    "         \"Prosciutto\", \"Salami\"]\r\n",
    "\r\n",
    "menu_tokens_list = [nlp(item) for item in menu] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the menu items into the matcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"MENU\", menu_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_test_on = \"The Il Purista sandwich has become a staple of my life. Mozzarella, basil, prosciutto, roasted red peppers and balsamic vinaigrette blend into a front runner for the best sandwich in the valley. Goes great with sparkling water or a beer. DeFalco's also has other Italian fare such as a delicious meatball sub and classic pastas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token number 2: Purista\n",
      "Token number 16: prosciutto\n",
      "Token number 57: meatball\n"
     ]
    }
   ],
   "source": [
    "review_doc = nlp(text_to_test_on)\r\n",
    "matches = matcher(review_doc)\r\n",
    "for match in matches:\r\n",
    "   print(f\"Token number {match[1]}: {review_doc[match[1]:match[2]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching on the whole dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\r\n",
    "item_ratings = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cant run this block as dont have data\r\n",
    "\r\n",
    "for idx, review in data.iterrows():\r\n",
    "    doc = nlp(review.text)\r\n",
    "    matches = matcher(doc)\r\n",
    "    \r\n",
    "    found_items = set([doc[match[1]:match[2]].lower_ for match in matches])\r\n",
    "\r\n",
    "    for item in found_items:\r\n",
    "        item_ratings[item].append(review.stars)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7907318c2678644a2c014b9018cb77fdbde3102e73d33f90e5edf5bfc480bfb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}